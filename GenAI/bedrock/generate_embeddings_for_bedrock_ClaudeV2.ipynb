{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ../dependencies/boto3-1.26.140-py3-none-any.whl --quiet\n",
    "%pip install ../dependencies/botocore-1.29.140-py3-none-any.whl --quiet\n",
    "%pip install python-dotenv boto3 langchain==0.0.249 PyPdf  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "boto_bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    endpoint_url='https://bedrock.us-west-2.amazonaws.com'\n",
    ")\n",
    "\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "br_embeddings = BedrockEmbeddings(client=boto_bedrock)\n",
    "# br_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-tg1-large\", \n",
    "#               model_kwargs ={\n",
    "#                 \"textGenerationConfig\": {\n",
    "#                    \"maxTokenCount\": 4096,\n",
    "#                    \"stopSequences\": [],\n",
    "#                    \"temperature\":0,\n",
    "#                    \"topP\":1\n",
    "#                 },\n",
    "#               },\n",
    "#               client=boto_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-17 16:51:37--  https://docs.spring.io/spring-framework/docs/6.0.8/reference/pdf/spring-framework.pdf\n",
      "Resolving docs.spring.io (docs.spring.io)... 104.20.3.65, 104.20.2.65\n",
      "Connecting to docs.spring.io (docs.spring.io)|104.20.3.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20829650 (20M) [application/pdf]\n",
      "Saving to: ‘spring-framework.pdf’\n",
      "\n",
      "spring-framework.pd 100%[===================>]  19.86M  10.1MB/s    in 2.0s    \n",
      "\n",
      "2023-08-17 16:51:39 (10.1 MB/s) - ‘spring-framework.pdf’ saved [20829650/20829650]\n",
      "\n",
      "--2023-08-17 16:51:39--  https://docs.spring.io/spring-boot/docs/3.1.2/reference/pdf/spring-boot-reference.pdf\n",
      "Resolving docs.spring.io (docs.spring.io)... 104.20.3.65, 104.20.2.65\n",
      "Connecting to docs.spring.io (docs.spring.io)|104.20.3.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17299408 (16M) [application/pdf]\n",
      "Saving to: ‘spring-boot-reference.pdf’\n",
      "\n",
      "spring-boot-referen 100%[===================>]  16.50M  9.92MB/s    in 1.7s    \n",
      "\n",
      "2023-08-17 16:51:41 (9.92 MB/s) - ‘spring-boot-reference.pdf’ saved [17299408/17299408]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://docs.spring.io/spring-framework/docs/6.0.8/reference/pdf/spring-framework.pdf\n",
    "!wget https://docs.spring.io/spring-boot/docs/3.1.2/reference/pdf/spring-boot-reference.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# # Multiple file -  Load PDF\n",
    "# loaders = [\n",
    "#     PyPDFLoader(\"https://docs.spring.io/spring-framework/docs/6.0.8/reference/pdf/spring-framework.pdf\"),\n",
    "#     PyPDFLoader(\"https://docs.spring.io/spring-boot/docs/3.1.2/reference/pdf/spring-boot-reference.pdf\")\n",
    "#     # Add more pdf files into this array,\n",
    "\n",
    "# ]\n",
    "# docs = []\n",
    "# for loader in loaders:\n",
    "#     docs.extend(loader.load())\n",
    "\n",
    "# # Split\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size = 2000,\n",
    "#     chunk_overlap = 400,\n",
    "#     separators=[\"\\n\", \"\\r\\n\", \"\\r\", \"\\t\", \" \"]\n",
    "# )\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "# # print(len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_split_pdf_files(file_names, chunk_size=512, chunk_overlap=50, separators=[\"\\n\", \"\\r\\n\", \"\\r\", \"\\t\", \" \"]):\n",
    "    \"\"\"\n",
    "    Load and split multiple PDF files into smaller chunks of text.\n",
    "\n",
    "    Args:\n",
    "    file_names (list): A list of file names to load.\n",
    "    chunk_size (int): The maximum size of each text chunk.\n",
    "    chunk_overlap (int): The number of characters to overlap between adjacent text chunks.\n",
    "    separators (list): A list of characters to use as separators when splitting the text.\n",
    "\n",
    "    Returns:\n",
    "    A list of text chunks.\n",
    "    \"\"\"\n",
    "    # Load PDF files\n",
    "    loaders = [PyPDFLoader(file_name) for file_name in file_names]\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    # Split text into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=separators\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981\n"
     ]
    }
   ],
   "source": [
    "file_names = [\"spring-framework.pdf\", \"spring-boot-reference.pdf\"]\n",
    "splits = load_and_split_pdf_files(file_names)\n",
    "\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9981"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# myframe = pd.DataFrame()\n",
    "# myframe['page_content'] = list(map(lambda x:x.page_content, splits))\n",
    "# myframe['metadata'] = list(map(lambda x:x.metadata, splits))\n",
    "# myframe.to_parquet('documents/spring_docs.parquet')\n",
    "\n",
    "# docs_from_parquet = pd.read_parquet('documents/spring_docs.parquet')\n",
    "# from langchain.schema.document import Document\n",
    "# # fill dataframe with one row per object, one attribute per column\n",
    "# docs_from_parquet['docs'] = docs_from_parquet.apply(lambda row: Document(page_content=row.page_content, metadata=row.metadata), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def save_documents_to_parquet(documents, file_path):\n",
    "    \"\"\"\n",
    "    Save a list of documents to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "    documents (list): A list of Document objects.\n",
    "    file_path (str): The file path to save the Parquet file to.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the list of documents\n",
    "    df = pd.DataFrame({\n",
    "        'page_content': [doc.page_content for doc in documents],\n",
    "        'metadata': [doc.metadata for doc in documents]\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a Parquet file\n",
    "    df.to_parquet(file_path)\n",
    "\n",
    "def read_documents_from_parquet(file_path):\n",
    "    \"\"\"\n",
    "    Read a list of documents from a Parquet file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The file path to read the Parquet file from.\n",
    "\n",
    "    Returns:\n",
    "    A list of Document objects.\n",
    "    \"\"\"\n",
    "    # Read the DataFrame from the Parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Create a list of Document objects from the DataFrame\n",
    "    documents = [Document(page_content=row['page_content'], metadata=row['metadata']) for _, row in df.iterrows()]\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Spring Framework Documentation\\nRod Johnson, Juergen Hoeller, Keith Donald, Colin Sampaleanu, Rob Harrop,\\nThomas Risberg, Alef Arendsen, Darren Davison, Dmitriy Kopylenko, Mark\\nPollack, Thierry Templier, Erwin Vervaet, Portia Tung, Ben Hale, Adrian Colyer,\\nJohn Lewis, Costin Leau, Mark Fisher, Sam Brannen, Ramnivas Laddad, Arjen\\nPoutsma, Chris Beams, Tareq Abedrabbo, Andy Clement, Dave Syer, Oliver\\nGierke, Rossen Stoyanchev, Phillip Webb, Rob Winch, Brian Clozel, Stephane' metadata={'page': 0, 'source': 'spring-framework.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Save the list of documents to a Parquet file\n",
    "save_documents_to_parquet(splits, 'documents/spring_docs.parquet')\n",
    "\n",
    "# Read the list of documents from the Parquet file\n",
    "documents = read_documents_from_parquet('documents/spring_docs.parquet')\n",
    "\n",
    "# Print the first document\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Spring Framework Documentation\\nRod Johnson, Juergen Hoeller, Keith Donald, Colin Sampaleanu, Rob Harrop,\\nThomas Risberg, Alef Arendsen, Darren Davison, Dmitriy Kopylenko, Mark\\nPollack, Thierry Templier, Erwin Vervaet, Portia Tung, Ben Hale, Adrian Colyer,\\nJohn Lewis, Costin Leau, Mark Fisher, Sam Brannen, Ramnivas Laddad, Arjen\\nPoutsma, Chris Beams, Tareq Abedrabbo, Andy Clement, Dave Syer, Oliver\\nGierke, Rossen Stoyanchev, Phillip Webb, Rob Winch, Brian Clozel, Stephane', metadata={'page': 0, 'source': 'spring-framework.pdf'}),\n",
       " Document(page_content='Nicoll, Sebastien Deleuze, Jay Bryant, Mark Paluch\\nVersion 6.0.8', metadata={'page': 0, 'source': 'spring-framework.pdf'}),\n",
       " Document(page_content='Table of Contents\\n1. Legal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa02\\n2. Spring Framework Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa03\\n2.1. What We Mean by \"Spring\" . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa03', metadata={'page': 1, 'source': 'spring-framework.pdf'}),\n",
       " Document(page_content='2.2. History of Spring and the Spring Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa03\\n2.3. Design Philosophy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa04\\n2.4. Feedback and Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa05', metadata={'page': 1, 'source': 'spring-framework.pdf'}),\n",
       " Document(page_content='2.5. Getting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa05\\n3. Core Technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa06\\n3.1. The IoC Container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \\xa06', metadata={'page': 1, 'source': 'spring-framework.pdf'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_embeddings_to_parquet(embeddings, file_path):\n",
    "    \"\"\"\n",
    "    Save a numpy array of embeddings to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "    embeddings (numpy.ndarray): A numpy array of embeddings.\n",
    "    file_path (str): The file path to save the Parquet file to.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the numpy array of embeddings\n",
    "    df = pd.DataFrame(embeddings)\n",
    "\n",
    "    # Save the DataFrame to a Parquet file\n",
    "    df.to_parquet(file_path)\n",
    "\n",
    "def load_embeddings_from_parquet(file_path):\n",
    "    \"\"\"\n",
    "    Load a numpy array of embeddings from a Parquet file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The file path to read the Parquet file from.\n",
    "\n",
    "    Returns:\n",
    "    A numpy array of embeddings.\n",
    "    \"\"\"\n",
    "    # Read the DataFrame from the Parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Convert the DataFrame to a numpy array of embeddings\n",
    "    embeddings = df.to_numpy()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore_faiss_aws:created=<langchain.vectorstores.faiss.FAISS object at 0x16c3d0c10>::\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore_faiss_aws = FAISS.from_documents(\n",
    "    documents=splits[:1000],\n",
    "    embedding = br_embeddings, \n",
    "    #**k_args\n",
    ")\n",
    "\n",
    "print(f\"vectorstore_faiss_aws:created={vectorstore_faiss_aws}::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Chromadb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Loading the PDF into the Vector DB with a resulting Vector Collection Count -  9981\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "# Load the vector DB\n",
    "persist_directory = \"./data/spring-reference\"\n",
    "# import tiktoken\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=br_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Completed Loading the PDF into the Vector DB with a resulting Vector Collection Count - \" , vectordb._collection.count())\n",
    "# 500 documents in the collection : 1m: 36s\n",
    "# 1000 documents in the collection : 2m: 58s\n",
    "# 2000 documents in the collection : 5m: 18s\n",
    "# 5000 documents in the collection : 14m: 36s\n",
    "# 9981 documents in the collection : 29m: 52s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install pinecone-client -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),  # find at app.pinecone.io\n",
    "    environment=os.getenv(\"PINECONE_ENV\"),  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"langchain-demo\"\n",
    "\n",
    "# First, check if our index already exists. If it doesn't, we create it\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "      name=index_name,\n",
    "      metric='cosine',\n",
    "      dimension=1536  \n",
    ")\n",
    "# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_qa_chain():\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=br_embeddings\n",
    "    )\n",
    "\n",
    "    print(vectordb._collection.count())\n",
    "    llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto_bedrock, model_kwargs={\"max_tokens_to_sample\":2000})\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectordb.as_retriever()\n",
    "    )\n",
    "\n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.chains import RetrievalQA\n",
    "def get_qa_chain_for_titan():\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=br_embeddings\n",
    "    )\n",
    "\n",
    "    print(vectordb._collection.count())\n",
    "    llm = Bedrock(model_id=\"amazon.titan-tg1-large\", client=boto_bedrock, model_kwargs={\"maxTokenCount\":2000})\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectordb.as_retriever()\n",
    "    )\n",
    "\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "# CREATE QA Chain\n",
    "qa_chain_titan = get_qa_chain_for_titan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The latest stable version of the Spring Framework is 6.2.2 and the latest stable version of Spring Boot is 2.6.3.\n",
      " a step-by-step migration guide for Boot 1.0 and Java to Boot 2.0 and Kotlin, is a sample project that demonstrates how to migrate an existing Spring Boot 1.0 application to Boot 2.0 and Kotlin. The project includes detailed instructions and code examples to help you upgrade your application step by step.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question1 = \"What is latest Spring Framework version and spring boot version you know about?\"\n",
    "result = qa_chain_titan({\"query\": question1})\n",
    "print(result[\"result\"])\n",
    "\n",
    "question1 = \"tell me more about a  A step-by-step migration guide for Boot 1.0 and Java to Boot 2.0 and Kotlin?\"\n",
    "result = qa_chain_titan({\"query\": question1})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981\n",
      " Based on the SDK output, the latest available version of Spring Boot is 3.1.2. The latest version of Spring Framework is 6.0, which is used in Spring Boot 3.x releases. Spring Framework 6.0 upgrades to Jakarta EE 9 APIs and is fully compatible with Java EE servers like Tomcat 10+, Jetty 11, and Undertow 2.3.\n",
      " Here are some key details about the spring-kotlin-deepdive sample project, which provides a step-by-step migration from Spring Boot 1.0 + Java to Spring Boot 2.0 + Kotlin:\n",
      "\n",
      "- It demonstrates migrating a simple Spring Boot 1.0 Java application to Spring Boot 2.0 Kotlin in small incremental steps. \n",
      "\n",
      "- Each step is tagged in Git so you can see the exact changes between steps.\n",
      "\n",
      "- It starts with a basic Spring Boot 1.0 Java app and eventually ends up as a Spring Boot 2.0 Kotlin app, while retaining the same functionality.\n",
      "\n",
      "- Along the way it converts Java configuration to Kotlin DSL, Java classes to Kotlin classes, converts tests from JUnit 4 + Mockito to JUnit 5, Switches from Maven to Gradle, upgrades Spring versions, adopts new Spring Boot 2.0 features, etc.\n",
      "\n",
      "- The readme file provides an overview of each step in the migration and what was changed or accomplished.\n",
      "\n",
      "- Overall it serves as a great tutorial and reference for incrementally migrating a Spring Boot Java app to Kotlin in a step-wise fashion.\n",
      "\n",
      "Does this help summarize the key points of the spring-kotlin-deepdive sample project? Let me know if you need any clarification or have additional questions!\n"
     ]
    }
   ],
   "source": [
    "qa_chain = get_qa_chain()\n",
    "\n",
    "question1 = \"What is latest Spring Framework version and spring boot version you know about?\"\n",
    "result = qa_chain({\"query\": question1})\n",
    "print(result[\"result\"])\n",
    "\n",
    "question1 = \"tell me more about a  A step-by-step migration guide for Boot 1.0 and Java to Boot 2.0 and Kotlin?\"\n",
    "result = qa_chain({\"query\": question1})\n",
    "print(result[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
